\documentclass[sigconf]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}
\begin{document}
\twocolumn
\title{Schema Extraction of JSON Reproduction}
\author{Ilnaz Tayebi}
\email{tayebi01@ads.uni-passau.de}
\affiliation{%
  \institution{University of Passau}
  \city{Passau}
  \country{Germany}
}
\maketitle
\section*{abstract}
This paper presents a report on the project of reproducing the Schema Extraction of JSON, an approach for extracting schemas from JSON and Extended JSON document collections.Due to the fact that the project used the same source code \cite{SONSchemaDiscovery2013} and dataset as the original project named ``An Approach for Schema Extraction of JSON and Extended JSON Document Collections'' \cite{8424731}, it considers as a reproducible effort. The report summarizes the key results of the reproduction project, and evacuation average processing time and discusses the challenges encountered during the reproduction effort. The importance of using a docker file and GitHub repository in creating a reproducible package is also explained. The paper concludes by discussing the differences between Repeat, Reproducing, and Replicating and why the project is considered as reproduction.
 \end{abstract}
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

% 
\section*{Introduction}
In computer science, reproducibility engineering is a crucial aspect that ensures research results can be verified and reused by other scientists. The purpose of this report is to detail a project I completed as part of the Reproducibility Engineering course. My aim was to create a reproducible package for the project ``An Approach for Schema Extraction of JSON and Extended JSON Document Collections'' \cite{8424731}. This report describes the reproduction project details, summarizes the key results, encounters challenges in the reproduction effort, differentiates between repeat, reproduce, and replicate, and justifies why my project focuses on reproduction only.


\section*{Project Description}
The project I have worked on is about creating a reproducible package for a pre-existing project named "Json schema discovery".This  pre-existing project presents a solution for extracting a schema from a JSON or Extended JSON document collection stored in a NoSQL document-oriented database, specifically MongoDB. The authors of the paper address the issue of handling large volumes of data without an explicit data schema and present an approach that aggregates the data to obtain a schema for each distinct structure in the collection. The final output of the approach is a global schema in JSON Schema format, generated by grouping these individual schemas into a hierarchical data structure. The project is implemented using Angular and experiments conducted on real datasets, such as DBPedia and Foursquare, show that the accuracy of the generated schemas is equal to or even better than related work.
The project has a GitHub repository and an article about it. Based on the related article, they considered three experiments to evaluate the quality of the generated schemas by JSON Schema Discovery. Different collections of JSON documents stored in MongoDB were used on each of them\cite{8424731}. These experiments are Quality of JSON document mapping for JSON Schema, Processing Time Evaluation, and Comparison with Related Work. In order to do the experiment they used three different datasets which are not accessible easily. Additionally, when I started to reproduce the project, no license was allocated to this project.

\section*{Reproduction Effort}
In this section, I will describe my reproduction effort in detail. The project I worked on is considered a reproduction and not a repetition or replication because I used the same source code and the same data as the main project.
I used Docker for packaging the project because of its ability to provide a consistent and reproducible environment for the application to run in. Packaging the project in a Docker container, enables me to include all of its dependencies, libraries, and configuration files, making it possible to distribute the application as a single unit. This made the deployment, scaling, and management of the application much easier, as the container can run on any host with the Docker runtime installed. Additionally, the use of containers offered benefits such as the isolation of the application from other applications and the host system, improving stability and project reproducibility over a long time.
The first step was creating a docker file for running the client side of the project. Next, I have to enable the API to connect to MongoDB. This forced me to use the docker-compose which allows us the ability to run different services at a time. 
Despite this, automating all the steps of the project considers Three main steps. These steps are as follows insert datasets into MongoDB, provide a script that runs all the steps of generating jason schema and refine the returned result in order to present it in the report.
In order to insert datasets into MongoDB, I defined the extra service in docker-compose named mongo_seed and used mongorestore  command to import BJSON files into MongoDB.
For simulating the all steps of json schema discovery I provide a script that runs all three steps of schema discovery besides the account creation and  authentication process for having a valid token. Finally, I write a small python code for generating the final result for presenting in the report.



\subsection{Why Reproduction is Important}

The ability to reproduce scientific experiments is crucial for the validity and reliability of scientific findings. It is also essential for scientific progress, as it allows researchers to build upon existing knowledge, test hypotheses, and validate theories. Reproducibility is also important for verifying the reliability and accuracy of research results and for avoiding errors or misunderstandings.
In this project, I considered reproduction as the key aspect of reproducibility engineering. This was because the project I was trying to reproduce was already published and available on GitHub. By following the steps outlined in the project's documentation, I was able to recreate the project's environment and results with a high degree of accuracy. This demonstrates the importance of reproducibility in ensuring the validity and reliability of scientific findings.

\begin{table}
  \caption{RESULTS FOR FOURSQUARE DATASETS}
  \label{tab:freq}
   \include{tablefoursquare.tex}
\end{table}
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\subsection{Challenges Encountered}

During the reproduction effort, I encountered several challenges. Firstly, the documentation of the original project is not well prepared, which led to the challenge of finding a compatible version of dependencies for the project. However, in the Readme file of the project repositories, there is a list of dependencies but the version of the dependencies is not mentioned.
Although we have access to the Package.json file, the project cannot build based on a version of dependencies in Package.json. In order to find the best matches for all dependencies I have reviewed the git commits of the original project, which brings me to stick to Node version 6.11.2. Additionally, the version of  "rotating-file-stream" in the package.json is not compatible with the rest of the packages. As a result, I provide a patch file to rewrite the  "rotating-file-stream"  version.

The second main challenge was finding the dataset which is used in the original project. Since I intend to reproduce the project which means having a different team project, but the same experimental, I spent a sizeable amount of time finding the same datasets the authors of the project used. The article of the project named and referenced three different datasets, but none of them are accessible with the mentioned references. In the end, I had to send an email to the author of the project to request the dataset and I received a dataset after a couple of weeks. Despite this, the license for the project is not allocated and I have to ask the authors for sending me a license  which takes almost one month to send it.

Additionally, Although there are lots of explanations in the article about how Jason discovery schema algorithm is implemented, there is no documentation about how to use the application. The illustration of this is that, after creating an account and login into the application, you will encounter several forms with no description of the fields. Besides the language of the application is Portuguese which makes the application's form much vaguer. In order to find out how the application works I investigate the source code of the project.

Finally, I encountered unexpected unknown errors while working on the project. After two days of troubleshooting, I found out that the owner of the repository had made some commits three days ago. To resolve this issue, I had to check out a specific commit in my docker file after cloning the repository. This issue brings me to understand the importance of choosing the exact version of the project at the first starting point of the reproduction project. It is highly important to decide whether you want to start your project based on which branch and commit to the original project since the original team may work at the same time on the project and you are not aware.

\section{Conclusion}

In conclusion, reproducibility is a crucial aspect of the field of computer science and research. It ensures that the experiments and results of a project can be repeated and validated by others. In this project, I attempted to create a reproducible package for a JSON Schema Discovery project, which required me to overcome various challenges such as finding the compatible version of packages and the dataset used in the project.
I used a docker file to dockerize the project and a GitHub repository to store the source code and the docker file. I also used Zenodo and Dio to archive the reproducible package and ensure its longevity.

By providing a reproducible package, I have ensured that the results and the methodology of the project can be validated and replicated by others in the future. This helps to increase trust in the results and ensures that the scientific literature remains accurate and reliable.
In this report, I also discussed the different levels of reproducibility and the importance of having a reproducible package in the field of computer science. By using latex and knitr, I have shown the results of my experiment in an organized and professional manner, making it easier for others to understand and follow my work.

Overall, this project has emphasized the importance of reproducibility in computer science and research and has provided me with a better understanding of the challenges and benefits of creating a reproducible package.


\bibliographystyle{ACM-Reference-Format}
\bibliography{report-bibliography}
\appendix


\end{document}
\endinput
